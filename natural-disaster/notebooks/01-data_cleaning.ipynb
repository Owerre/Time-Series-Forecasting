{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Construction of Time Series Data\n",
    "\n",
    "The data for the natural disaster occurrence can be found at [emdat.be](https://www.emdat.be). We have extracted a univariate time series data for yearly occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore deprecated warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pyspark modules\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spark session\n",
    "spark = SparkSession.builder.appName(\"project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data size: (15901, 20)\n",
      "+----+---------+-------------------+-------------+\n",
      "|year|continent|      disaster_type|no_occurrence|\n",
      "+----+---------+-------------------+-------------+\n",
      "|1900|   Africa|            Drought|          7.0|\n",
      "|1900|     Asia|            Drought|          7.0|\n",
      "|1902| Americas|         Earthquake|         10.0|\n",
      "|1902| Americas|  Volcanic activity|         10.0|\n",
      "|1902| Americas|  Volcanic activity|         10.0|\n",
      "|1903| Americas|Mass movement (dry)|         12.0|\n",
      "|1903|   Africa|  Volcanic activity|         12.0|\n",
      "|1904|     Asia|              Storm|          4.0|\n",
      "|1905| Americas|Mass movement (dry)|          8.0|\n",
      "|1905|     Asia|         Earthquake|          8.0|\n",
      "|1906| Americas|         Earthquake|         13.0|\n",
      "|1906| Americas|         Earthquake|         13.0|\n",
      "|1906|   Europe|              Flood|         13.0|\n",
      "|1906|   Europe|              Flood|         13.0|\n",
      "|1906|     Asia|              Storm|         13.0|\n",
      "|1907|     Asia|         Earthquake|          3.0|\n",
      "|1907|     Asia|           Epidemic|          3.0|\n",
      "|1908| Americas|Mass movement (dry)|          3.0|\n",
      "|1909|     Asia|              Storm|         17.0|\n",
      "|1909|     Asia|              Storm|         17.0|\n",
      "+----+---------+-------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "base_path = ' '\n",
    "df = spark.read.csv(base_path + '/natural-disaster/data/emdat_public_cleaned.csv', inferSchema = True, header = True) \n",
    "df.createOrReplaceTempView(\"raw_table\") # create table for sql query\n",
    "\n",
    "# print data size and display sample\n",
    "print(\"Data size:\", (df.count(), len(df.columns)))\n",
    "cols = ['year', 'continent', 'disaster_type', 'no_occurrence']\n",
    "df.select(cols).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     year  tot_occurrence\n",
       "0    1959              33\n",
       "1    1990             303\n",
       "2    1903              12\n",
       "3    1975              67\n",
       "4    1977             141\n",
       "..    ...             ...\n",
       "117  1929               5\n",
       "118  1928              17\n",
       "119  1933              11\n",
       "120  2021             101\n",
       "121  1993             267\n",
       "\n",
       "[122 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>tot_occurrence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1959</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1990</td>\n      <td>303</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1903</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1975</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1977</td>\n      <td>141</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>1929</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>1928</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>1933</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>2021</td>\n      <td>101</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>1993</td>\n      <td>267</td>\n    </tr>\n  </tbody>\n</table>\n<p>122 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df_sel = spark.sql(\"select year, count(*) as tot_occurrence from raw_table group by 1\")\n",
    "df_sel = df_sel.toPandas()\n",
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "df_sel.to_csv('../data/ts_yearly.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}